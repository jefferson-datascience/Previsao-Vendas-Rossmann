{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.0 Pacotes e Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulação de Dados\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Carregamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_fato = pd.read_csv('../BaseDados/DadosTreino.csv', delimiter=',', low_memory=False)\n",
    "df1_dimensao = pd.read_csv('../BaseDados/DadosLoja.csv', delimiter=',', low_memory=False)\n",
    "df1 = df1_fato.merge(df1_dimensao, how='left', on='Store')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Seleção dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o nosso objetivo é realizar a previsão dos próximos 6 dias de vendas das lojas, podemos, após um entendimento das variáveis, verificar quais delas fazem sentido. \n",
    "\n",
    "1. Ao analisar, temos que duas variávies não fazem sentido para nós. São elas: 'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval'.\n",
    "2. Obtendo apenas os dados dos últimos 7 dias de vendas.\n",
    "\n",
    "Portanto, vamos remover essas variáveis do nosso dataset e aplicar os filtros, de modo que, iniciemos nosso trabalho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[df1['Open'] == 1].drop(columns=['Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval'], axis=1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Engenharia de Atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo dessa etapa é conseguir ver a possibilidade de informações que estão 'escondidas' nos dados. Podemos obervar que o nosso dataset é bem limitado, sendo assim, vamos inicialmente construir nossa variável que é as vendas dos próximos 6 dias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cópia dos Dados\n",
    "df2 = df1.copy()\n",
    "\n",
    "\n",
    "# Tratamento de Data\n",
    "# Ajuste da Variável Data\n",
    "df2['Date'] = pd.to_datetime(df2['Date'], format='%Y-%m-%d')\n",
    "\n",
    "# Ordenamento dos Dados\n",
    "df2_sort = df2.sort_values(by=['Store', 'Date'], ascending=True).reset_index(drop=True).copy()\n",
    "\n",
    "max_data = df2_sort.groupby('Store')['Date'].transform('max')\n",
    "df2_sort = df2_sort[df2_sort['Date'] >= (max_data - pd.Timedelta(days=6))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que a variável stateHolyday é uma variável categórica, vamos criar variáveis dummies de modo trazer essas variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['StateHoliday_b', 'StateHoliday_c'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Gerando as variáveis dummies para os feriados\u001b[39;00m\n\u001b[32m      2\u001b[39m df2_sort = (\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_dummies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf2_sort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mStateHoliday\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mint64\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43m              \u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mStateHoliday_0\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mStateHoliday_b\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mStateHoliday_c\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m               .rename(columns={\u001b[33m'\u001b[39m\u001b[33mStateHoliday_a\u001b[39m\u001b[33m'\u001b[39m:\u001b[33m'\u001b[39m\u001b[33mPublicHoliday\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mStateHoliday_b\u001b[39m\u001b[33m'\u001b[39m:\u001b[33m'\u001b[39m\u001b[33mEasterHoliday\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mStateHoliday_c\u001b[39m\u001b[33m'\u001b[39m:\u001b[33m'\u001b[39m\u001b[33mChristmas_Holiday\u001b[39m\u001b[33m'\u001b[39m}))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jeffe\\Documents\\Projetos\\ProjetosCienciaDados\\Previsao-Vendas-Rossmann\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:5588\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5440\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5441\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5442\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5449\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5450\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5451\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5452\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5453\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5586\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5587\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5588\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5589\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5590\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5591\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5592\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5593\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5594\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5595\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5596\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jeffe\\Documents\\Projetos\\ProjetosCienciaDados\\Previsao-Vendas-Rossmann\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:4807\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4805\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4806\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4807\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4809\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4810\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jeffe\\Documents\\Projetos\\ProjetosCienciaDados\\Previsao-Vendas-Rossmann\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:4849\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4847\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4848\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4849\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4850\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4852\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4853\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jeffe\\Documents\\Projetos\\ProjetosCienciaDados\\Previsao-Vendas-Rossmann\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7098\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7096\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7097\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7098\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7099\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7100\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
      "\u001b[31mKeyError\u001b[39m: \"['StateHoliday_b', 'StateHoliday_c'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Gerando as variáveis dummies para os feriados\n",
    "df2_sort = (pd.get_dummies(data=df2_sort, columns=['StateHoliday'], dtype=np.int64)\n",
    "              .drop(columns=['StateHoliday_0', 'StateHoliday_b', 'StateHoliday_c'], axis=1)\n",
    "              .rename(columns={'StateHoliday_a':'PublicHoliday', 'StateHoliday_b':'EasterHoliday', 'StateHoliday_c':'Christmas_Holiday'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vendas do último dia\n",
    "df2_sort['SalesLastDay'] = df2_sort.groupby('Store')['Sales'].shift(1)\n",
    "\n",
    "# Média dos últimos 7 dias\n",
    "df2_sort['MeanSalesLastSevenDays'] = df2_sort.groupby('Store')['Sales'].shift(1).rolling(7).mean()\n",
    "\n",
    "# Total de vendas dos últimos 7 dias\n",
    "df2_sort['TotalSalesLastSevenDays'] = df2_sort.groupby('Store')['Sales'].shift(1).rolling(7).sum()\n",
    "\n",
    "# Total de Promoções aplicadas nos últimos 7 dias\n",
    "df2_sort['TotalPromoLastSevenDays'] = df2_sort.groupby('Store')['Promo'].shift(1).rolling(7).sum()\n",
    "\n",
    "# Total de Feriados Públicos nos últimos 7 dias\n",
    "df2_sort['TotalPublicHolidaysLastSevenDays'] = df2_sort.groupby('Store')['PublicHoliday'].shift(1).rolling(7).sum()\n",
    "\n",
    "# Total de promoções 2 ativadas nos últimos 7 dias\n",
    "df2_sort['TotalPromo2LastSevenDays'] = df2_sort.groupby('Store')['Promo2'].shift(1).rolling(7).sum()\n",
    "\n",
    "# Total de feriados escolares no últimos 7 dias\n",
    "df2_sort['TotalSchoolHolidayLastSevenDays'] = df2_sort.groupby('Store')['SchoolHoliday'].shift(1).rolling(7).sum()\n",
    "\n",
    "# Anos de Competição\n",
    "df2_sort['YearsCompetition'] = df2_sort['Date'].max().year - df2_sort['CompetitionOpenSinceYear']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui vamos selecionar apenas as variáveis que façam sentido para o nosso problema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_sort = df2_sort[['Store', 'StoreType', 'Assortment', 'CompetitionDistance', 'YearsCompetition', 'Sales', 'Customers', 'Promo','Promo2', 'PublicHoliday', 'SalesLastDay',\n",
    "                     'MeanSalesLastSevenDays', 'TotalSalesLastSevenDays', 'TotalPromoLastSevenDays', 'TotalPromo2LastSevenDays', 'TotalSchoolHolidayLastSevenDays', 'TotalPublicHolidaysLastSevenDays']]\n",
    "\n",
    "# Renomeando colunas\n",
    "df2_sort = df2_sort.rename(columns={'Sales':'SalesDay', 'Customers': 'CustomersDay', 'PromoDay':'Promo2Day', 'PublicHoliday':'PublicHolidayDay'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que a nossa variável alvo nossa é a TotalSalesNextSixDays. Sendo assim, nossa variável alvo não pode ser nula. Além disso, de modo que tenhamos o máximo de informação consolidada, vamos eliminar a quantidade as variáveis nulas em relação a soma móveis, pois pelo fato de ser nulo, quer dizer que não há informações disponíveis, logo, não está trazendo o conteúdo que precisamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminando os dados desnecessários\n",
    "df2_sort_clean = df2_sort.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Previsão das Próximos 6 dias de Faturamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cópia segura dos dados\n",
    "df2_sort_clean = df2_sort_clean.copy()\n",
    "\n",
    "# Instanciando o modelo\n",
    "modelo_preditivo = pkl.load(open('../Modelos/XGBRegressorFinalVersao1.pkl', 'rb'))\n",
    "\n",
    "# Realizando a Predição\n",
    "predicao = modelo_preditivo.predict(df2_sort_clean)\n",
    "\n",
    "# Armazenando os dados no Dataset\n",
    "df2_sort_clean.loc[:,'PredictionSalesNextSexWeek'] = np.round(predicao.tolist(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Salvando os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_sort_clean.to_parquet(path='../DadosPredicao/BasePredita.parquet', engine='fastparquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
